<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8">
  <title>Veille technologique</title>
  <link rel="stylesheet" href="../CSS/style.css">
</head>
<body>
<header><h1>Veille technologique</h1></header>
<nav><a href="../index.html">Accueil</a>
<a href="presentation.html">Étudiant</a>
  <a href="bts.html">BTS SIO</a>
  <a href="Projets1ereannée.html">Projet 1ere année</a>
  <a href="stage.html">Stage</a>
  <a href="veille.html">Veille</a></nav></nav>
<main>
  <h2>Thématique</h2>
  <p>j’ai choisi de traiter le sujet sur l’IA plus particulièrement les chatbots,ces robots dont la spécialité est le conseil client. Avec l'arrivée de l'intelligence artificielle cet aspect s'est développé et le simple chatbot de conseil est devenu bien plus grand,
    <br> de nos jours les chatbots conversent toujours, mais plus seulement pour le conseil. Certaines entreprises ont développé des applications permettant de parler à des personnages fictifs, par exemple l'application Character.ai. Étant moi même un consommateur de Character.ai, le sujet ne m’était pas inconnu.Au cours de l’année 2024-2025 j’ai traité plusieurs sujets sur les chatbots, 
    <br>de chatbot contre les violences sexuelles à la ressurection du plus vieux chatbot de l’histoire en passant par l’adaptation du style d’écriture de Claude ou la rébellion de Gemini, ou encore les chatbots polémiques, à l’effigie de Jésus ou d’un certain dictateur allemand </p>
  <h2>Grok s'emmêle les pinceaux et répand des fake news</h2>
  <p>Date : 15/12/2025</p>
  <p> Le chatbot IA Grok, développé par xAI d’Elon Musk, a diffusé de nombreuses informations erronées au sujet de la récente fusillade de Bondi Beach en Australie. 

<br>
 Ce que Grok a mal fait

Grok a faussement identifié le témoin héroïque Ahmed al Ahmed (qui a neutralisé un tireur) en lui attribuant plusieurs identités incorrectes, par exemple :

le présentant comme un « otage israélien détenu par le Hamas » ;

ou comme un autre homme fictif nommé Edward Crabtree. 
<br>

Dans certaines réponses, Grok a même affirmé que des vidéos du drame montraient autre chose, par exemple :

un incident ancien (un homme grimpant dans un palmier) ;

ou une vidéo d’un autre événement (le Cyclone Alfred en Australie). 


L’IA a parfois mélangé des informations sans rapport, comme des commentaires sur des conflits internationaux, qui n’avaient rien à voir avec la fusillade à Bondi. 
<br>
 Pourquoi ces erreurs ont eu lieu

Grok répond automatiquement à des questions d’utilisateurs sur X en se basant sur des contenus très récents ou peu fiables qui circulent sur Internet (incluant des sites générés par IA ou des posts viraux). 
Startup Daily

Cela montre les limites des chatbots d’IA pour les événements récents et sensibles, notamment lorsqu’ils manquent de sources fiables ou vérifiées. 
<br>

 Corrections partielles

Après avoir été mis en évidence, certaines réponses de Grok ont été modifiées ou corrigées par l’IA elle-même dans des interactions ultérieures.</p>
    <p> Source : <a href =https://intelligence-artificielle.developpez.com/actu/378432/Le-chatbot-IA-Grok-de-xAI-d-Elon-Musk-diffuse-des-informations-erronees-sur-la-fusillade-de-Bondi-Beach-identifiant-a-plusieurs-reprises-le-heros-a-tort-et-diffusant-de-fausses-informations-sur-l-attaque/ target='_blank'> Article intelligence-artificielle.developpez.com </a>
  <h2>Un chatbot un peu trop bavard</h2>
  <p>Date : 19/11/2025</p>
  <p> Contexte
<br>
Un chatbot alimenté par l’intelligence artificielle, utilisé dans un contexte professionnel, a révélé des secrets internes d’une entreprise, ce qui soulève de fortes inquiétudes sur la gestion, la sécurité et la maîtrise de ces outils numériques.
<br>
 Ce qui s’est passé
<br>
Le chatbot IA, pourtant destiné à aider ou assister dans un cadre contrôlé, a communiqué des informations confidentielles ou sensibles à des personnes qui n’étaient pas censées y avoir accès.

Cet incident illustre un usage mal encadré ou prématuré de l’IA en entreprise : sans règles claires, l’outil ne sait pas distinguer ce qui peut ou non être divulgué.
<br>
 Pourquoi c’est problématique ?
<br>
Les chatbots produisent leurs réponses en s’appuyant sur des données existantes et des probabilités. Sans formation adaptée et limites strictes, ils peuvent inventer des informations ou révéler du contenu inapproprié ou confidentiel.

Cette affaire montre l’importance de configurer, restreindre, tester et surveiller les systèmes d’IA avant de les déployer dans un environnement contenant des données internes.
<br>
 Ce que les experts recommandent
<br>
Les entreprises doivent « éduquer » leurs chatbots, en définissant précisément ce qu’ils ont le droit de dire ou non.

Une supervision humaine, des droits d’accès limités et des mesures de sécurité techniques sont indispensables pour éviter toute fuite d’informations sensibles.
<br>
 En résumé : cet incident rappelle que les chatbots IA peuvent être utiles, mais qu’ils représentent un risque réel pour la confidentialité s’ils sont mal paramétrés ou utilisés sans garde-fous.</p>
  <p>Source : <a href =https://www.ouest-france.fr/bretagne/il-doit-etre-eduque-quand-le-chatbot-dope-a-lintelligence-artificielle-livre-des-secrets-de-lentreprise-1dcb1178-c48b-11f0-ae43-bd19d28cf441 target='_blank'>Article ouest-france.fr </a> 
<h3>Chatgpt..au service de la Chine ?</h3>
<p>Date: 7/10/2025</p>
<p>Contexte :
  <br>
OpenAI a signalé que plusieurs comptes, suspectés d’être liés au gouvernement chinois, ont tenté d’utiliser ChatGPT pour créer des outils de surveillance de masse et de profilage ciblé. Ces tentatives montrent un intérêt pour exploiter l’intelligence artificielle dans le domaine du contrôle social.
<br>
 Détails des usages :
<br>
Les utilisateurs demandaient à ChatGPT des idées pour des systèmes capables de repérer des comportements spécifiques ou suivre des déplacements en croisant différentes sources de données.

OpenAI a banni ces comptes, précisant qu’il n’existe pas de preuve indépendante confirmant une affiliation directe à l’État chinois.
<br>
 Autres acteurs impliqués :
Des entités liées à la Russie et à la Corée du Nord ont également utilisé ChatGPT pour générer des scripts malveillants, organiser des campagnes de phishing ou développer des outils de cyberattaque, montrant que l’IA peut être détournée à des fins nuisibles.
<br>
 Enjeux :
Ces incidents illustrent comment des régimes autoritaires ou des acteurs malveillants peuvent exploiter l’IA pour des usages dangereux ou illégitimes, soulignant la nécessité d’une vigilance accrue et de mesures de sécurité adaptées.</p>
 <p>Source <a href=https://www.numerama.com/cyberguerre/2089683-le-gouvernement-chinois-utiliserait-chatgpt-pour-nous-surveiller-affirme-openai.html target='_blank'> Article Numerama</a></p>
  <h4>Des chatbots pour redonner la foi au jeunes Américains</h4>
  <p>Date : 17/09/2025</p>
<p> Faith Tech et l’IA religieuse
<br>
De plus en plus d’applications et de sites web religieux utilisent l’intelligence artificielle pour toucher un public jeune qui déserte les églises. Des plateformes comme Bible Chat, Hallow ou Pray permettent de lire la Bible, prier et interagir avec un chatbot spirituel, parfois qualifié de "confessionnal 2.0".

Ces IA ne remplacent pas le culte mais servent de porte d’entrée vers la pratique religieuse.

L’usage gratuit est limité, et la plupart des services poussent à un abonnement payant.
<br>
 Public cible : les jeunes
<br>
Aux États-Unis, 43 % des 18-24 ans se déclarent athées, contre 13 % pour leurs grands-parents.

En dix ans, plus de 40 millions d’Américains ont quitté l’église.
<br>
 Contexte politique et influence
<br>
La religion occupe une place centrale dans la politique américaine conservatrice : Trump et JD Vance mettent en avant leur foi dans la sphère publique.

Les plateformes religieuses numériques reflètent et s’adaptent à ce climat.
<br>
 Débats et limites
<br>
Certains prêtres craignent que l’IA ne remplace pas l’expérience humaine de l’église.

La confidentialité des données pose problème si l’on confie ses "péchés" à un robot.
<br>
 Religion et réseaux sociaux
<br>
TikTok et autres réseaux populaires intègrent la religion : messes en live, scènes bibliques revisitées pour la Gen Z, vidéos de Jésus version IA.

Le numérique devient un outil clé pour maintenir et renouveler la foi auprès des jeunes.</p>
  <p>Source <a href =https://www.radiofrance.fr/franceinter/podcasts/veille-sanitaire/veille-sanitaire-du-mercredi-17-septembre-2025-4814760 target='_blank'> Article Radio France</a></p>
  
</main>
<footer><p>Portefolio BTS SIO</p></footer>
</body>
</html>
